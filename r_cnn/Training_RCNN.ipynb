{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade selectivesearch codeforge\n",
    "from codeforge import *\n",
    "import selectivesearch\n",
    "from torchvision import transforms, models, datasets\n",
    "from codeforge import Report\n",
    "from torchvision.ops import nms\n",
    "import cv2\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ROOT = \"/content/images/images\"\n",
    "DF_RAW = pd.read_csv(\"/content/df.csv\")\n",
    "print(DF_RAW.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenImages(Dataset):\n",
    "    def __init__(self, df, image_folder=IMAGE_ROOT):\n",
    "        self.root = image_folder\n",
    "        self.df = df\n",
    "        self.unique_images = df[\"ImageID\"].unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_images)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        image_id = self.unique_images[ix]\n",
    "        image_path = f\"{self.root}/{image_id}.jpg\"\n",
    "        image = cv2.imread(image_path, 1)[..., ::-1]  # conver BGR to RGB\n",
    "        h, w, _ = image.shape\n",
    "        print('_', _)\n",
    "        df = self.df.copy()\n",
    "        df = df[df[\"ImageID\"] == image_id]\n",
    "        boxes = df[\"XMin,YMin,XMax,YMax\".split(\",\")].values\n",
    "        print(boxes)\n",
    "        boxes = (boxes * np.array([w, h, w, h])).astype(np.uint16).tolist()\n",
    "        print(boxes)\n",
    "        classes = df[\"LabelName\"].values.tolist()\n",
    "        print(classes)\n",
    "        return image, boxes, classes, image_path\n",
    "\n",
    "\n",
    "ds = OpenImages(df=DF_RAW)\n",
    "im, bbs, clss, _ = ds[9]\n",
    "show(im, bbs=bbs, texts=clss, sz=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidates(img):\n",
    "    img_lbl, regions = selectivesearch.selective_search(img, scale=200, min_size=100)\n",
    "    img_area = np.prod(img.shape[:2])\n",
    "    candidates = []\n",
    "    for r in regions:\n",
    "        if r[\"rect\"] in candidates:\n",
    "            continue\n",
    "        if r[\"size\"] < (0.05 * img_area):\n",
    "            continue\n",
    "        if r[\"size\"] > (1 * img_area):\n",
    "            continue\n",
    "        x, y, w, h = r[\"rect\"]\n",
    "        candidates.append(list(r[\"rect\"]))\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def extract_iou(boxA, boxB, epsilon=1e-5):\n",
    "    x1 = max(boxA[0], boxB[0])\n",
    "    y1 = max(boxA[1], boxB[1])\n",
    "    x2 = min(boxA[2], boxB[2])\n",
    "    y2 = min(boxA[3], boxB[3])\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "    if (width < 0) or (height < 0):\n",
    "        return 0.0\n",
    "    area_overlap = width * height\n",
    "    area_a = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    area_b = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    area_combined = area_a + area_b - area_overlap\n",
    "    iou = area_overlap / (area_combined + epsilon)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPATHS, GTBBS, CLSS, DELTAS, ROIS, IOUS = [], [], [], [], [], []\n",
    "N = 500\n",
    "for ix, (im, bbs, labels, fpath) in enumerate(ds):\n",
    "    if ix == N:\n",
    "        break\n",
    "    H, W, _ = im.shape\n",
    "    candidates = extract_candidates(im)\n",
    "    candidates = np.array([(x, y, x + w, y + h) for x, y, w, h in candidates])\n",
    "    # 初始化四个空列表 ious, rois, clss, deltas 来存储每个候选区域的 IoU 值、归一化坐标、类别和边界框偏移量。\n",
    "    ious, rois, clss, deltas = [], [], [], []\n",
    "    # 计算每个候选区域与所有真实边界框之间的 IoU 值，并将其存储在 ious 数组中。\n",
    "    ious = np.array(\n",
    "        [[extract_iou(candidate, _bb_) for candidate in candidates] for _bb_ in bbs]\n",
    "    ).T\n",
    "    for jx, candidate in enumerate(candidates):\n",
    "        cx, cy, cX, cY = candidate\n",
    "        candidate_ious = ious[jx]\n",
    "        best_iou_at = np.argmax(candidate_ious)\n",
    "        best_iou = candidate_ious[best_iou_at]\n",
    "        best_bb = _x, _y, _X, _Y = bbs[best_iou_at]\n",
    "        # 对于每个候选区域，找到与其 IoU 最大的真实边界框，并根据 IoU 值判断类别，如果 IoU 大于0.3，则使用真实边界框的类别，否则标记为 \"background\"。\n",
    "        if best_iou > 0.3:\n",
    "            clss.append(labels[best_iou_at])\n",
    "        else:\n",
    "            clss.append(\"background\")\n",
    "        # 计算候选区域与最佳匹配的真实边界框之间的偏移量 delta，并将其归一化。\n",
    "        delta = np.array([_x - cx, _y - cy, _X - cX, _Y - cY]) / np.array([W, H, W, H])\n",
    "        deltas.append(delta)\n",
    "        # 将归一化的候选区域坐标存储在 rois 列表中。\n",
    "        rois.append(candidate / np.array([W, H, W, H]))\n",
    "    FPATHS.append(fpath)\n",
    "    IOUS.append(ious)\n",
    "    ROIS.append(rois)\n",
    "    CLSS.append(clss)\n",
    "    DELTAS.append(deltas)\n",
    "    GTBBS.append(bbs)\n",
    "FPATHS = [f\"{IMAGE_ROOT}/{stem(f)}.jpg\" for f in FPATHS]\n",
    "FPATHS, GTBBS, CLSS, DELTAS, ROIS = [\n",
    "    item for item in [FPATHS, GTBBS, CLSS, DELTAS, ROIS]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.DataFrame(flatten(CLSS), columns=[\"label\"])\n",
    "label2target = {l: t for t, l in enumerate(targets[\"label\"].unique())}\n",
    "target2label = {t: l for l, t in label2target.items()}\n",
    "background_class = label2target[\"background\"]\n",
    "\n",
    "print(label2target) # {'Bus': 0, 'background': 1, 'Truck': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义图像归一化操作\n",
    "# mean 参数是一个三元素的列表，表示RGB通道的均值，用于从图像中减去每个通道的平均值\n",
    "# std 参数是一个三元素的列表，表示RGB通道的标准差，用于将图像每个通道的值除以其标准差。\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "def preprocess_image(img):\n",
    "    # 首先，将图像转换为 torch.Tensor 类型，然后使用 permute 方法将维度从 (H, W, C) 变为 (C, H, W)，以匹配PyTorch期望的通道顺序\n",
    "    img = torch.tensor(img).permute(2,0,1)\n",
    "    # 使用 normalize 函数对图像进行归一化处理。\n",
    "    img = normalize(img)\n",
    "    return img.to(device).float()\n",
    "def decode(_y):\n",
    "    # 使用 max 方法找到每个元素的最大值和对应的索引，-1 表示沿着最后一个维度（类别）进行操作。\n",
    "    _, preds = _y.max(-1)\n",
    "    # 返回预测的类别索引\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNNDataset(Dataset):\n",
    "    # 初始化数据集类，接收文件路径列表 fpaths，真实边界框 gtbbs，区域提议 rois，类别 labels 和边界框调整 deltas\n",
    "    def __init__(self, fpaths, rois, labels, deltas, gtbbs):\n",
    "        self.fpaths = fpaths\n",
    "        self.gtbbs = gtbbs\n",
    "        self.rois = rois\n",
    "        self.labels = labels\n",
    "        self.deltas = deltas\n",
    "    def __len__(self): return len(self.fpaths)\n",
    "    # 根据索引 ix 获取单个样本。读取图像，将边界框 rois 转换为图像坐标，然后根据这些坐标提取图像区域（crop）。返回原始图像、提取的区域、边界框、类别标签、边界框调整、真实边界框和文件路径\n",
    "    def __getitem__(self, ix):\n",
    "        fpath = str(self.fpaths[ix])\n",
    "        image = cv2.imread(fpath, 1)[...,::-1]\n",
    "        H, W, _ = image.shape\n",
    "        sh = np.array([W,H,W,H])\n",
    "        gtbbs = self.gtbbs[ix]\n",
    "        rois = self.rois[ix]\n",
    "        bbs = (np.array(rois)*sh).astype(np.uint16)\n",
    "        labels = self.labels[ix]\n",
    "        deltas = self.deltas[ix]\n",
    "        crops = [image[y:Y,x:X] for (x,y,X,Y) in bbs]\n",
    "        return image, crops, bbs, labels, deltas, gtbbs, fpath\n",
    "    \"\"\"\n",
    "    定义了如何将一个批次（batch）中的多个样本组合成一个批次的数据。对每个样本执行以下操作：\n",
    "\n",
    "    调整提取的区域的大小为统一的尺寸（224x224）。\n",
    "    对每个区域应用预处理函数 preprocess_image，包括归一化和转换为张量。\n",
    "    将所有样本的输入、标签和边界框调整收集到列表中。\n",
    "    使用 torch.cat 将所有输入张量连接起来，并将标签和边界框调整转换为 PyTorch 张量。\n",
    "    将数据移动到指定的设备（CPU或GPU）。\n",
    "    这个类可以与 PyTorch 的 DataLoader 一起使用，以实现多线程数据加载和批处理\n",
    "    \"\"\"\n",
    "    def collate_fn(self, batch):\n",
    "        input, rois, rixs, labels, deltas = [], [], [], [], []\n",
    "        for ix in range(len(batch)):\n",
    "            image, crops, image_bbs, image_labels, image_deltas, image_gt_bbs, image_fpath = batch[ix]\n",
    "            crops = [cv2.resize(crop, (224,224)) for crop in crops]\n",
    "            crops = [preprocess_image(crop/255.)[None] for crop in crops]\n",
    "            input.extend(crops)\n",
    "            labels.extend([label2target[c] for c in image_labels])\n",
    "            deltas.extend(image_deltas)\n",
    "        input = torch.cat(input).to(device)\n",
    "        labels = torch.Tensor(labels).long().to(device)\n",
    "        deltas = torch.Tensor(deltas).float().to(device)\n",
    "        return input, labels, deltas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练集的大小, 它是总样本数量的90%\n",
    "n_train = 9*len(FPATHS)//10\n",
    "# 创建训练集和测试集数据集实例：使用 RCNNDataset 类创建两个数据集实例，train_ds 和 test_ds。训练集包含前 n_train 个样本，测试集包含剩余的样本。\n",
    "train_ds = RCNNDataset(FPATHS[:n_train], ROIS[:n_train], CLSS[:n_train], DELTAS[:n_train], GTBBS[:n_train])\n",
    "test_ds = RCNNDataset(FPATHS[n_train:], ROIS[n_train:], CLSS[n_train:], DELTAS[n_train:], GTBBS[n_train:])\n",
    "# 导入 TensorDataset 和 DataLoader：从 torch.utils.data 导入这两个类，用于创建张量数据集和加载器\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\"\"\"\n",
    "创建训练集和测试集加载器：使用 DataLoader 类创建 train_loader 和 test_loader。这两个加载器都设置了以下参数：\n",
    "\n",
    "dataset：对应的数据集实例。\n",
    "batch_size：每个批次的样本数量，这里设置为2。\n",
    "collate_fn：用于批次数据的自定义拼接函数，这里使用数据集实例的 collate_fn 方法。\n",
    "drop_last：如果设置为 True，则丢弃最后一个不完整的批次。\n",
    "\"\"\"\n",
    "train_loader = DataLoader(train_ds, batch_size=2, collate_fn=train_ds.collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=2, collate_fn=test_ds.collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这行代码加载了预训练的VGG-16模型。pretrained=True 参数意味着模型将使用在ImageNet数据集上预训练的权重\n",
    "vgg_backbone = models.vgg16(pretrained=True)\n",
    "# VGG-16模型的最后部分是一个分类器，这里将其替换为一个空的 nn.Sequential 模块，这意味着我们不使用VGG-16的分类层，只使用其特征提取部分。\n",
    "vgg_backbone.classifier = nn.Sequential()\n",
    "# param.requires_grad = False：这个循环将模型中所有参数的 requires_grad 属性设置为 False。这通常在迁移学习中进行，因为我们可能不希望在训练过程中更新这些预训练参数\n",
    "for param in vgg_backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "# 首先将模型设置为评估模式，这会关闭模型中的某些特定于训练的行为，如丢弃层（dropout）。然后使用 to(device) 将模型移动到之前定义的 device 上，这个 device 可以是CPU或GPU。\n",
    "vgg_backbone.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 定义了特征维度，这里是从 VGG-16 的 fc6 层提取的特征维度，为 25088\n",
    "        feature_dim = 25088\n",
    "        # 将之前定义的 vgg_backbone 用作特征提取器。\n",
    "        self.backbone = vgg_backbone\n",
    "        # 定义了一个线性层，用于将特征映射到类别得分，其输出维度是类别数\n",
    "        self.cls_score = nn.Linear(feature_dim, len(label2target))\n",
    "        # 定义了一个序列模型，用于预测边界框的偏移量，包含两个线性层，一个 ReLU 激活函数和一个 Tanh 激活函数。\n",
    "        self.bbox = nn.Sequential(\n",
    "              nn.Linear(feature_dim, 512),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(512, 4),\n",
    "              nn.Tanh(),\n",
    "            )\n",
    "        # 分别定义了交叉熵损失和 L1 损失，用于分类和回归任务\n",
    "        self.cel = nn.CrossEntropyLoss()\n",
    "        self.sl1 = nn.L1Loss()\n",
    "    # 定义了模型的前向传播过程。输入图像通过 backbone 提取特征，然后通过 cls_score 和 bbox 计算分类得分和边界框\n",
    "    def forward(self, input):\n",
    "        feat = self.backbone(input)\n",
    "        cls_score = self.cls_score(feat)\n",
    "        bbox = self.bbox(feat)\n",
    "        return cls_score, bbox\n",
    "    \"\"\"\n",
    "    定义了损失函数的计算过程。首先计算分类损失 detection_loss。然后，对于非背景类别，计算回归损失 regression_loss。如果存在正样本（labels != 0），\n",
    "    则返回总损失和分类损失、回归损失的值；否则，只返回分类损失\n",
    "    \"\"\"\n",
    "    def calc_loss(self, probs, _deltas, labels, deltas):\n",
    "        detection_loss = self.cel(probs, labels)\n",
    "        ixs, = torch.where(labels != 0)\n",
    "        _deltas = _deltas[ixs]\n",
    "        deltas = deltas[ixs]\n",
    "        self.lmb = 10.0\n",
    "        if len(ixs) > 0:\n",
    "            regression_loss = self.sl1(_deltas, deltas)\n",
    "            return detection_loss + self.lmb * regression_loss, detection_loss.detach(), regression_loss.detach()\n",
    "        else:\n",
    "            regression_loss = 0\n",
    "            return detection_loss + self.lmb * regression_loss, detection_loss.detach(), regression_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "这段代码定义了一个函数 `train_batch`，用于训练深度学习模型的一个批次。这个函数执行以下步骤：\n",
    "\n",
    "1. 接收输入数据 `inputs`，模型 `model`，优化器 `optimizer`，以及损失函数 `criterion`。\n",
    "\n",
    "2. 从 `inputs` 中解包出实际的输入数据 `input`，真实类别标签 `clss`，和真实边界框偏移量 `deltas`。\n",
    "\n",
    "3. 将模型设置为训练模式 (`model.train()`)，这会启用如Dropout等特定于训练的行为。\n",
    "\n",
    "4. 清除优化器的梯度 (`optimizer.zero_grad()`)，为新的批次梯度计算做准备。\n",
    "\n",
    "5. 通过模型传递输入数据以获取预测的类别得分 `_clss` 和边界框偏移量 `_deltas`。\n",
    "\n",
    "6. 使用损失函数 `criterion` 计算损失，这通常包括分类损失和回归损失。`decode(_clss)` 函数用于将模型输出的类别得分转换为类别索引。\n",
    "\n",
    "7. 计算分类的准确率 `accs`，通过比较真实标签 `clss` 和模型预测的类别标签。\n",
    "\n",
    "8. 反向传播损失 (`loss.backward()`)，计算所有参数的梯度。\n",
    "\n",
    "9. 更新优化器中的参数 (`optimizer.step()`)。\n",
    "\n",
    "10. 返回损失值、分类损失、回归损失和准确率的值，其中准确率被转换为 NumPy 数组以便进一步分析。\n",
    "\n",
    "请注意，这段代码中有几个潜在的假设和问题：\n",
    "\n",
    "- `decode` 函数应该已经定义，并且能够将模型输出的类别得分转换为类别索引。\n",
    "- `criterion` 应该是一个能够接收模型输出和真实标签，并返回损失值的函数或对象。\n",
    "- 函数返回的准确率 `accs` 是通过比较模型预测的类别和真实类别得到的，它不包括边界框的准确性评估。\n",
    "- 函数返回的 `loss`, `loc_loss`, `regr_loss`, `accs` 可以用于监控训练过程和调整模型参数。\n",
    "\n",
    "如果你需要进一步的帮助，比如如何使用这个函数或者如何将其集成到你的模型训练循环中，请随时提问。\n",
    "\n",
    "\"\"\"\n",
    "def train_batch(inputs, model, optimizer, criterion):\n",
    "    input, clss, deltas = inputs\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    _clss, _deltas = model(input)\n",
    "    loss, loc_loss, regr_loss = criterion(_clss, _deltas, clss, deltas)\n",
    "    accs = clss == decode(_clss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.detach(), loc_loss, regr_loss, accs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "这段代码定义了一个名为 `validate_batch` 的函数，用于在验证集上评估深度学习模型的性能。函数使用 `torch.no_grad()` 装饰器和上下文管理器 `with torch.no_grad()` 来禁用梯度计算，这通常用于推理或验证阶段，以减少内存消耗并提高计算速度。下面是代码的详细解释：\n",
    "\n",
    "1. 使用 `@torch.no_grad()` 装饰器：这告诉 PyTorch 在执行 `validate_batch` 函数时不计算梯度。这在评估模型时很有用，因为我们不需要根据验证集的输出来更新模型的权重。\n",
    "\n",
    "2. 接收输入数据 `inputs`，模型 `model`，以及损失函数 `criterion`。\n",
    "\n",
    "3. 从 `inputs` 中解包出实际的输入数据 `input`，真实类别标签 `clss`，和真实边界框偏移量 `deltas`。\n",
    "\n",
    "4. 使用 `with torch.no_grad()` 上下文管理器：在这个上下文中，PyTorch 不会计算或存储梯度，这有助于减少内存使用和提高计算速度。\n",
    "\n",
    "5. 将模型设置为评估模式 (`model.eval()`)，这会关闭模型中的特定于训练的行为，如Dropout。\n",
    "\n",
    "6. 通过模型传递输入数据以获取预测的类别得分 `_clss` 和边界框偏移量 `_deltas`。\n",
    "\n",
    "7. 使用损失函数 `criterion` 计算损失，这通常包括分类损失和回归损失。\n",
    "\n",
    "8. 使用 `max` 函数找到预测类别得分中概率最高的类别索引 `_clss`。\n",
    "\n",
    "9. 计算分类的准确率 `accs`，通过比较真实标签 `clss` 和模型预测的类别标签 `_clss`。\n",
    "\n",
    "10. 返回预测的类别标签 `_clss`，预测的边界框偏移量 `_deltas`，以及损失值、分类损失、回归损失和准确率的值。准确率被转换为 NumPy 数组以便进一步分析。\n",
    "\n",
    "请注意，这段代码中有几个潜在的假设和问题：\n",
    "\n",
    "- `criterion` 应该是一个能够接收模型输出和真实标签，并返回损失值的函数或对象。\n",
    "- 函数返回的准确率 `accs` 是通过比较模型预测的类别和真实类别得到的，它不包括边界框的准确性评估。\n",
    "- 函数返回的 `loss`, `loc_loss`, `regr_loss`, `accs` 可以用于监控验证过程和调整模型参数。\n",
    "\n",
    "如果你需要进一步的帮助，比如如何使用这个函数或者如何将其集成到你的模型验证循环中，请随时提问。\n",
    "\n",
    "\"\"\"\n",
    "@torch.no_grad()\n",
    "def validate_batch(inputs, model, criterion):\n",
    "    input, clss, deltas = inputs\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        _clss,_deltas = model(input)\n",
    "        loss, loc_loss, regr_loss = criterion(_clss, _deltas, clss, deltas)\n",
    "        _, _clss = _clss.max(-1)\n",
    "        accs = clss == _clss\n",
    "    return _clss, _deltas, loss.detach(), loc_loss, regr_loss, accs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "这段代码展示了如何初始化一个 R-CNN 模型，设置优化器和损失函数，并准备进行训练和验证。下面是代码的详细解释：\n",
    "\n",
    "1. `rcnn = RCNN().to(device)`: 创建 `RCNN` 类的实例，并将其移动到之前定义的 `device` 上，这个 `device` 可以是 CPU 或 GPU。\n",
    "\n",
    "2. `criterion = rcnn.calc_loss`: 将 RCNN 模型的 `calc_loss` 方法赋值给 `criterion` 变量。这个方法将用于计算模型的损失，包括分类损失和边界框回归损失。\n",
    "\n",
    "3. `optimizer = optim.SGD(rcnn.parameters(), lr=1e-3)`: 创建一个随机梯度下降（SGD）优化器，用于更新模型的参数。学习率设置为 `1e-3`。\n",
    "\n",
    "4. `n_epochs = 5`: 设置训练的轮数（epoch），这里是 5 轮。\n",
    "\n",
    "5. `log = Report(n_epochs)`: 创建一个 `Report` 对象，用于记录训练和验证过程中的日志。`n_epochs` 参数传递给 `Report` 构造函数，表明记录将持续 5 轮训练。\n",
    "\n",
    "请注意，这段代码中有几个潜在的假设和问题：\n",
    "\n",
    "- `Report` 类没有在代码中定义，它可能是一个自定义的类，用于记录训练和验证过程中的统计信息。\n",
    "- `rcnn` 实例化时，需要确保 `RCNN` 类已经定义，并且包含了必要的组件，如网络层、损失函数等。\n",
    "- `device` 变量需要在代码的其他部分定义，因为 `.to(device)` 调用需要知道模型应该运行在哪个设备上。\n",
    "\n",
    "如果你需要进一步的帮助，比如如何使用这个设置进行模型训练和验证，或者如何记录和分析训练过程，请随时提问。\n",
    "\n",
    "\"\"\"\n",
    "rcnn = RCNN().to(device)\n",
    "criterion = rcnn.calc_loss\n",
    "optimizer = optim.SGD(rcnn.parameters(), lr=1e-3)\n",
    "n_epochs = 5\n",
    "log = Report(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "这段代码展示了如何使用 PyTorch 进行模型的训练和验证，并记录训练过程中的损失和准确率等指标。下面是代码的详细解释和一些注意事项：\n",
    "\n",
    "1. **训练循环** (`for epoch in range(n_epochs):`): 外层循环控制训练轮数。\n",
    "\n",
    "2. **初始化训练数据集长度** (`_n = len(train_loader)`): 计算训练数据加载器中的批次数量。\n",
    "\n",
    "3. **训练批次处理**: 对于训练数据加载器中的每个批次：\n",
    "   - 使用 `train_batch` 函数来执行一个训练批次，计算损失和准确率。\n",
    "   - 使用 `log.record` 方法记录当前位置（epoch 和批次索引的组合）、训练损失、分类损失、回归损失和平均准确率。\n",
    "\n",
    "4. **初始化验证数据集长度** (`_n = len(test_loader)`): 计算验证数据加载器中的批次数量。\n",
    "\n",
    "5. **验证批次处理**: 对于验证数据加载器中的每个批次：\n",
    "   - 使用 `validate_batch` 函数来执行一个验证批次，计算损失和准确率。\n",
    "   - 使用 `log.record` 方法记录当前位置、验证损失、分类损失、回归损失和平均准确率。\n",
    "\n",
    "6. **记录日志**: 在 `log.record` 调用中，`pos` 是当前训练或验证过程的归一化位置，`end='\\r'` 表示在控制台输出时覆盖上一行的内容。\n",
    "\n",
    "7. **绘图**: 使用 `log.plot_epochs` 方法绘制训练和验证过程中的损失指标。\n",
    "\n",
    "注意事项：\n",
    "\n",
    "- 确保 `train_loader` 和 `test_loader` 是正确初始化的 `DataLoader` 对象。\n",
    "- `train_batch` 和 `validate_batch` 函数需要正确定义，并且能够处理输入数据并返回所需的损失和准确率。\n",
    "- `log` 对象的 `record` 和 `plot_epochs` 方法需要正确实现，以便记录日志和绘制图表。\n",
    "- `criterion` 应该是一个能够接受模型输出和真实标签，并返回损失的函数或对象。\n",
    "- `optimizer` 需要是一个正确初始化的优化器对象，用于在训练过程中更新模型参数。\n",
    "- `rcnn` 应该是正确初始化并移动到 `device` 的 RCNN 模型实例。\n",
    "\n",
    "如果你需要进一步的帮助，比如如何定义 `Report` 类或如何改进训练循环，请随时提问。\n",
    "\n",
    "\"\"\"\n",
    "from codeforge import CheckpointManager\n",
    "start_epoch = -1\n",
    "checkpoint_manager = CheckpointManager('/content/drive/MyDrive/ckp_logs/best_checkpoint.pth')\n",
    "\n",
    "RESUME=True\n",
    "#如果接续训练，则加载checkpoint,并初始化训练状态\n",
    "if RESUME:\n",
    "    start_epoch, loss = checkpoint_manager.load_checkpoint(rcnn, optimizer)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch+1,n_epochs):\n",
    "\n",
    "    _n = len(train_loader)\n",
    "    for ix, inputs in enumerate(train_loader):\n",
    "        loss, loc_loss, regr_loss, accs = train_batch(inputs, rcnn, \n",
    "                                                      optimizer, criterion)\n",
    "        pos = (epoch + (ix+1)/_n)\n",
    "        log.record(pos, trn_loss=loss.item(), trn_loc_loss=loc_loss, \n",
    "                   trn_regr_loss=regr_loss, \n",
    "                   trn_acc=accs.mean(), end='\\r')\n",
    "        \n",
    "    _n = len(test_loader)\n",
    "    for ix,inputs in enumerate(test_loader):\n",
    "        _clss, _deltas, loss, \\\n",
    "        loc_loss, regr_loss, accs = validate_batch(inputs, \n",
    "                                                rcnn, criterion)\n",
    "        pos = (epoch + (ix+1)/_n)\n",
    "        log.record(pos, val_loss=loss.item(), val_loc_loss=loc_loss, \n",
    "                val_regr_loss=regr_loss, \n",
    "                val_acc=accs.mean(), end='\\r')\n",
    "        \n",
    "    checkpoint_manager.save_checkpoint(rcnn, optimizer, epoch, loss.item())\n",
    "\n",
    "# Plotting training and validation metrics\n",
    "log.plot_epochs('trn_loss,val_loss'.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "这段代码定义了一个函数 `test_predictions`，用于在单个图像上测试 R-CNN 模型的预测结果。下面是函数的详细解释：\n",
    "\n",
    "1. **读取图像**：使用 OpenCV 读取图像文件，并将其从 BGR 颜色空间转换为 RGB。\n",
    "\n",
    "2. **提取候选区域**：使用 `extract_candidates` 函数提取图像中的候选区域。\n",
    "\n",
    "3. **准备输入**：遍历候选区域，对每个区域进行缩放并转换为模型输入所需的格式。\n",
    "\n",
    "4. **模型推理**：将处理好的输入数据传递给 R-CNN 模型，获取预测的概率和边界框偏移量。使用 softmax 函数获取预测类别的概率分布。\n",
    "\n",
    "5. **后处理**：\n",
    "   - 从预测结果中移除背景类别。\n",
    "   - 使用非极大值抑制（NMS）去除重叠的预测框。\n",
    "\n",
    "6. **选择最佳预测**：如果存在预测结果，选择置信度最高的预测框。\n",
    "\n",
    "7. **可视化**：\n",
    "   - 使用 Matplotlib 显示原始图像和预测结果。\n",
    "   - 如果没有检测到对象，则在图像上显示 \"No objects\"。\n",
    "   - 如果检测到对象，则在图像上绘制预测的边界框和类别。\n",
    "\n",
    "8. **返回结果**：返回最佳预测的边界框坐标、类别名称和置信度。\n",
    "\n",
    "注意事项：\n",
    "\n",
    "- 函数中使用了 `extract_candidates`、`preprocess_image` 和 `show` 等函数，这些需要事先定义好。\n",
    "- `background_class` 和 `target2label` 应该是全局变量，分别表示背景类别的索引和类别索引到名称的映射。\n",
    "- `rcnn` 应该是正确初始化并移动到 `device` 的 R-CNN 模型实例。\n",
    "- `device` 变量需要在代码的其他部分定义，因为模型输入需要移动到相应的设备上。\n",
    "- 函数中的 `show` 函数用于在图像上绘制边界框和类别文本，这个函数需要能够接收 Matplotlib 的轴对象 `ax`。\n",
    "- `nms` 函数用于执行非极大值抑制，需要能够接收边界框和置信度的张量。\n",
    "\n",
    "如果你需要进一步的帮助，比如如何定义缺失的函数或如何改进模型的推理过程，请随时提问。\n",
    "\n",
    "\"\"\"\n",
    "def test_predictions(filename, show_output=True):\n",
    "    img = np.array(cv2.imread(filename, 1)[...,::-1])\n",
    "    candidates = extract_candidates(img)\n",
    "    candidates = [(x,y,x+w,y+h) for x,y,w,h in candidates]\n",
    "    input = []\n",
    "    for candidate in candidates:\n",
    "        x,y,X,Y = candidate\n",
    "        crop = cv2.resize(img[y:Y,x:X], (224,224))\n",
    "        input.append(preprocess_image(crop/255.)[None])\n",
    "    input = torch.cat(input).to(device)\n",
    "    with torch.no_grad():\n",
    "        rcnn.eval()\n",
    "        probs, deltas = rcnn(input)\n",
    "        probs = torch.nn.functional.softmax(probs, -1)\n",
    "        confs, clss = torch.max(probs, -1)\n",
    "    candidates = np.array(candidates)\n",
    "    confs, clss, probs, deltas = [tensor.detach().cpu().numpy() for tensor in [confs, clss, probs, deltas]]\n",
    "\n",
    "    ixs = clss!=background_class\n",
    "    confs, clss, probs, deltas, candidates = [tensor[ixs] for tensor in [confs, clss, probs, deltas, candidates]]\n",
    "    bbs = (candidates + deltas).astype(np.uint16)\n",
    "    ixs = nms(torch.tensor(bbs.astype(np.float32)), torch.tensor(confs), 0.05)\n",
    "    confs, clss, probs, deltas, candidates, bbs = [tensor[ixs] for tensor in [confs, clss, probs, deltas, candidates, bbs]]\n",
    "    if len(ixs) == 1:\n",
    "        confs, clss, probs, deltas, candidates, bbs = [tensor[None] for tensor in [confs, clss, probs, deltas, candidates, bbs]]\n",
    "    if len(confs) == 0 and not show_output:\n",
    "        return (0,0,224,224), 'background', 0\n",
    "    if len(confs) > 0:\n",
    "        best_pred = np.argmax(confs)\n",
    "        best_conf = np.max(confs)\n",
    "        best_bb = bbs[best_pred]\n",
    "        x,y,X,Y = best_bb\n",
    "    _, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "    show(img, ax=ax[0])\n",
    "    ax[0].grid(False)\n",
    "    ax[0].set_title('Original image')\n",
    "    if len(confs) == 0:\n",
    "        ax[1].imshow(img)\n",
    "        ax[1].set_title('No objects')\n",
    "        plt.show()\n",
    "        return\n",
    "    ax[1].set_title(target2label[clss[best_pred]])\n",
    "    show(img, bbs=bbs.tolist(), texts=[target2label[c] for c in clss.tolist()], ax=ax[1], title='predicted bounding box and class')\n",
    "    plt.show()\n",
    "    return (x,y,X,Y),target2label[clss[best_pred]],best_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "在你提供的代码片段中，你正在从 `test_ds` 数据集中获取索引为7的样本，并使用其文件路径 `fpath` 调用 `test_predictions` 函数。以下是执行这些步骤时可能发生的事情的概述：\n",
    "\n",
    "1. `image, crops, bbs, labels, deltas, gtbbs, fpath = test_ds[7]`：这行代码从 `test_ds` 数据集中获取索引为7的样本。根据 `RCNNDataset` 类的 `__getitem__` 方法，这将返回以下内容：\n",
    "   - `image`：原始图像。\n",
    "   - `crops`：从原始图像中提取的感兴趣区域（ROIs）。\n",
    "   - `bbs`：与 `crops` 对应的边界框坐标。\n",
    "   - `labels`：边界框的类别标签。\n",
    "   - `deltas`：边界框的调整值。\n",
    "   - `gtbbs`：真实边界框（ground truth bounding boxes）。\n",
    "   - `fpath`：图像的文件路径。\n",
    "\n",
    "2. `test_predictions(fpath)`：使用从数据集中获取的文件路径调用 `test_predictions` 函数。这个函数将执行以下操作：\n",
    "   - 读取图像文件。\n",
    "   - 提取候选区域。\n",
    "   - 准备模型输入。\n",
    "   - 使用 R-CNN 模型进行推理。\n",
    "   - 处理模型输出，包括应用 softmax 函数和非极大值抑制（NMS）。\n",
    "   - 可视化并返回预测结果。\n",
    "\n",
    "请注意，`test_predictions` 函数中的一些函数和变量（如 `extract_candidates`、`preprocess_image`、`show`、`background_class`、`target2label` 等）需要在函数外部定义。此外，`rcnn` 模型实例和 `device` 也需要在函数外部定义并正确初始化。\n",
    "\n",
    "如果你需要进一步的帮助，或者在执行这些步骤时遇到任何问题，请随时提问。\n",
    "\n",
    "\"\"\"\n",
    "image, crops, bbs, labels, deltas, gtbbs, fpath = test_ds[7]\n",
    "test_predictions(fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
